---
layout: page
title: "text processing"
#output: html_document
description: Learning to use R to process texts
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(tokenizers)
```
```{r}

text <- paste("Now, I understand that because it's an election season",
          "expectations for what we will achieve this year are low.",
          "But, Mister Speaker, I appreciate the constructive approach",
          "that you and other leaders took at the end of last year",
          "to pass a budget and make tax cuts permanent for working",
          "families. So I hope we can work together this year on some",
          "bipartisan priorities like criminal justice reform and",
          "helping people who are battling prescription drug abuse",
          "and heroin abuse. So, who knows, we might surprise the",
          "cynics again")

text
```
```{r}
words <- tokenize_words(text)

words
```

```{r}
length(words)
length(words[[1]])
```

```{r}
tab <- table(words[[1]])
tab <- data_frame(word = names(tab), count = as.numeric(tab))
tab
```
```{r}
arrange(tab, desc(count))
```
## Detecting Sentence Boundaries
```{r}
sentences <- tokenize_sentences(text)
sentences


```

```{r}
sentence_words <- tokenize_words(sentences[[1]])
sentence_words

length(sentence_words[[1]])
length(sentence_words[[2]])
length(sentence_words[[3]])
length(sentence_words[[4]])
```

```{r}
sapply(sentence_words, length)
```

